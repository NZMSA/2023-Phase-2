{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA 2023 Phase 2 - Part 3 (Example)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the well-known Iris dataset is used to build a classifier, which is then deployed onto Azure via the Azure Machine Learning Software Development Kit (SDK) and called via a real-time endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load necessary packages and modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running the code below for your own model**:\n",
    "1. Make sure that you're using scikit-learn version 1.1.* (* = any number). You can check this by running `import sklearn; print(sklearn.__version__)`. This is to ensure your model will work on Azure.\n",
    "    - If you don't, then install version 1.1.* into your virtual environment by running `pip install scikit-learn~=1.1.0`, or recreate your virtual environment using the [requirements.txt](../requirements.txt) file in this repository.\n",
    "    - After doing the above, restart your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Machine Learning SDK core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Scikit-learn and others\n",
    "from sklearn import datasets; iris = datasets.load_iris()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train and save a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training here is provided only as an example, it assumes you don't have a trained model already.\n",
    "\n",
    "**Before running the code below for your own model**:\n",
    "1. Load in your trained model, or copy the last line of the code below into the notebook where your trained model is located.\n",
    "2. Save your trained model as a .pkl file called model.pkl, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into a training set and a test set (test set not used in this example)\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and save model\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "pickle.dump(rfc, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and connect to workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running the code below for your own model**:\n",
    "1. Replace the path below with the path to your own config.json file that you downloaded in step 5 of [Getting Started with Azure Machine Learning](../0.%20Resources/docs/getting-started-with-azure-ml.md).\n",
    "\n",
    "After running the code below, a browser window should open where you have to sign in to Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path=\"config.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Register model onto Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running the code below for your own model**:\n",
    "1. Replace the model name below with an appropriate name for your model.\n",
    "2. Replace the model path below with the path to your own .pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model iris-random-forest\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(ws, model_name=\"iris-random-forest\", model_path=\"model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create entry script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registering a model only uploads it to Azure and doesn't let us run the model yet, so an entry script needs to be created that will run when the model receives data. For the Iris dataset, the entry script is in a file called [score.py](../3.%20Microsoft%20Azure/score.py) provided in this repository.\n",
    "\n",
    "**Before running the code below for your own model**:\n",
    "1. Create your own entry script by changing the variables below in [score.py](../3.%20Microsoft%20Azure/score.py):\n",
    "    - __model_name__: The name of the .pkl file to your one (assuming you've named it something other than model.pkl).\n",
    "    - __classes__: The classes dictionary to contain keys and values which match the way you have encoded labels (for classification), or to not use it and just return the result (for regression).\n",
    "\n",
    "**You don't need to change any other parts of the script** unless you want to do any other post-processing of results or receive any other errors, in which case please browse the Azure Machine Learning [troubleshooting documentation](https://learn.microsoft.com/en-gb/azure/machine-learning/how-to-troubleshoot-online-endpoints) or ask on Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create real-time endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After registering your model and creating an entry script, you can configure and deploy a real-time endpoint to run your model over the Internet and allow others to do as well. \n",
    "\n",
    "For Phase 2, we will do this in the Machine Learning Studio itself in a simplified manner as described below, but note that this can be done using the Azure Machine Learning SDK libraries as well.\n",
    "\n",
    "To create a real-time endpoint:\n",
    "\n",
    "1. Go into your [Model List](https://ml.azure.com/model/list) in the Machine Learning Studio (it should look something similar to [this list](../0.%20Resources/images/model_list.png) if you have registered your model as described above), and select the model you want to deploy.\n",
    "\n",
    "2. In the menu above, click _Deploy_ then _Real-time endpoint_. A wizard should open with a series of steps to complete.\n",
    "\n",
    "3. Click _Next_ on the Endpoint step.\n",
    "\n",
    "4. Click _Next_ on the Model step.\n",
    "\n",
    "5. Click _Next_ on the Deployment step.\n",
    "\n",
    "6. On the Environment step, under _Select scoring file and dependencies_, upload your entry script.\n",
    "\n",
    "7. On the Environment step, under _Dependencies_, search for the environment called _sklearn-1:1:7_ and select it.\n",
    "\n",
    "8. Click _Next_ on the Environment step.\n",
    "\n",
    "9. Click _Next_ on the Compute step.\n",
    "\n",
    "10. On the Traffic step, ensure that 100% of traffic goes to the model you want to deploy (in case you have deployed multiple models to the same endpoint).\n",
    "\n",
    "11. Click _Next_ on the Traffic step.\n",
    "\n",
    "12. On the Review step, check that you have configured everything as required (it should look similar to this [configuration](../0.%20Resources/images/model_deployment.png)).\n",
    "\n",
    "13. Click _Create_, then wait until your model has been deployed (this can take up to 15 minutes). Once it's deployed, you should see something similar to these [endpoint details](../0.%20Resources/images/model_deployment_complete.png). If the deployment fails, check the deployment logs (located in the _Deployment logs_ section, as shown in the previous image) for the exact error that caused it to fail (it may be something in your entry script, your .pkl file, or elsewhere), fix the error, then re-run the above steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test and share endpoint for marking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test and share your real-time endpoint for marking:\n",
    "1. Go to the _Consume_ tab of your endpoint\n",
    "2. Copy the Python code under the _Consumption option_ section into the notebook you plan to submit for this part\n",
    "2. In your Python code:\n",
    "    - Add your secondary key into the api_key variable by copying it from the _Consume_ tab\n",
    "    - Add input data into the data variable\n",
    "        - Note that in the [score.py](./score.py) entry script we have provided, the input data is an array of numbers which come from the value of a dictionary with the key being `data`, so the format of your input data will depend on how you've written your entry script\n",
    "        - Please refer to the code below to see how the input data is formatted\n",
    "3. Ensure that your input data and secondary key are present within the notebook so that the MSA team can test it for marking purposes\n",
    "\n",
    "The code below is copied from the _Consumption option_ section and updated as described above to call the deployed model for the Iris dataset. If you make the changes to the code below as described above, run it, and it returns a prediction, then you have successfully deployed your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[\"versicolor\"]'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data = {\n",
    "    \"data\": [[6.1, 2.8, 4.7, 1.2]]\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'https://msa2023-phase2-azure-bmftu.australiaeast.inference.ml.azure.com/score'\n",
    "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "api_key = ''\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'iris-random-forest-1' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please do not delete or turn off any resources until the MSA team has completed marking. Once we have finished marking, this will be announced on Discord, after which (to avoid incurring unnecessary costs):\n",
    "1. Delete your models and endpoints from [Machine Learning Studio](https://ml.azure.com/).\n",
    "1. Delete or turn off any resources you created, as explained in [this section](https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-azure-ml-in-a-day?view=azureml-api-2#delete-all-resources) of the Azure Machine Learning documentation."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdb671202a387ebf0bc7bf04476cbafa528fae566193c2efe94e2aaf8539be45"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
